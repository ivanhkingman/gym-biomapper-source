{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import time\n",
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import cmocean\n",
    "#from simple_agent import SimpleAtariAgent\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import dqn_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93df85d8e1e140f8b3c8cba61ae4e740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset the position to (0,0,0)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd67ceafdbd46df9cce44c65d98c811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\marte\\.conda\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From c:\\users\\marte\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('gym_biomapping:perfect_info_atari-v0', static=True, output='3D-matrix')\n",
    "agent = dqn_agent.DQNAgent(env, input=\"3D-matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset the position to (0,0,0)\n"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "next_action = agent.deliberate(obs)\n",
    "agent.render(obs, next_action)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "done = False\n",
    "while not done:\n",
    "    obs, reward, done, info = env.step(next_action)\n",
    "    #next_pos = agent.deliberate(obs)\n",
    "    agent.render(obs, next_action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For more reproduceable results, but consider changing\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "tf.set_random_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                      | 0/100 [00:00<?, ?episodes/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n",
      "Episode reward:  109.02322769165039\n",
      "WARNING:tensorflow:From c:\\users\\marte\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\callbacks\\tensorboard_v1.py:343: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|1             | 1/100 [00:11<19:14, 11.66s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|2             | 2/100 [00:23<18:55, 11.59s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  337.20257568359375\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|4             | 3/100 [00:34<18:32, 11.47s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  278.7209167480469\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  4%|5             | 4/100 [00:45<18:13, 11.39s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  145.62260627746582\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|7             | 5/100 [00:56<17:55, 11.33s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  265.55854415893555\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|8             | 6/100 [01:07<17:42, 11.31s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  179.99904251098633\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  7%|9             | 7/100 [01:19<17:34, 11.34s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  96.58406066894531\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|#1            | 8/100 [01:30<17:17, 11.28s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  132.4255256652832\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|#2            | 9/100 [01:41<17:05, 11.27s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  91.65714645385742\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 10%|#3           | 10/100 [01:52<16:52, 11.25s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  252.18023872375488\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|#4           | 11/100 [02:04<16:39, 11.23s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  144.16545009613037\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|#5           | 12/100 [02:15<16:25, 11.20s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  225.74450540542603\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 13%|#6           | 13/100 [02:26<16:13, 11.19s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  184.60885047912598\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|#8           | 14/100 [02:37<16:00, 11.17s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  268.39711570739746\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 15%|#9           | 15/100 [02:48<15:48, 11.16s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  244.92330169677734\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|##           | 16/100 [02:59<15:38, 11.17s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  270.49613761901855\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|##2          | 17/100 [03:11<15:26, 11.17s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  190.45767784118652\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 18%|##3          | 18/100 [03:22<15:15, 11.17s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  224.50894355773926\n",
      "Reset the position to (0,0,0)\n",
      "WARNING:tensorflow:From c:\\users\\marte\\.conda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|##4          | 19/100 [03:33<15:06, 11.19s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  89.76514267921448\n",
      "Reset the position to (0,0,0)\n",
      "Replay-memory sufficiently large - Started using neural network\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|##6          | 20/100 [04:02<22:11, 16.64s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  76.15397453308105\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 21%|##7          | 21/100 [04:55<36:07, 27.43s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  188.1548571586609\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|##8          | 22/100 [05:47<45:28, 34.98s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  228.95446395874023\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|##9          | 23/100 [06:40<51:47, 40.36s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  115.23102951049805\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 24%|###1         | 24/100 [07:32<55:32, 43.85s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  189.7302589416504\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|###2         | 25/100 [08:24<57:50, 46.28s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  143.9588451385498\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 26%|###3         | 26/100 [09:16<59:10, 47.98s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  95.44243717193604\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|###5         | 27/100 [10:08<59:48, 49.15s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  62.716190338134766\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|###        | 28/100 [11:00<1:00:03, 50.05s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  317.21851348876953\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 29%|###7         | 29/100 [11:52<59:51, 50.59s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  152.61414337158203\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|###9         | 30/100 [12:44<59:29, 51.00s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  191.79150390625\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|####         | 31/100 [13:36<59:01, 51.32s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  161.2552813887596\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 32%|####1        | 32/100 [14:28<58:21, 51.50s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  148.0075626373291\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|####2        | 33/100 [15:21<57:49, 51.78s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  153.58651065826416\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|####4        | 34/100 [16:13<57:02, 51.85s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  91.59129905700684\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 35%|####5        | 35/100 [17:05<56:18, 51.97s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  369.58792877197266\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|####6        | 36/100 [17:57<55:32, 52.07s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  345.119478225708\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 37%|####8        | 37/100 [18:49<54:38, 52.04s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  201.55811500549316\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|####9        | 38/100 [19:41<53:47, 52.06s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  103.34860610961914\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|#####        | 39/100 [20:34<53:00, 52.14s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  203.81663608551025\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 40%|#####2       | 40/100 [21:26<52:08, 52.14s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  490.54798126220703\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|#####3       | 41/100 [22:18<51:13, 52.09s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  88.60877418518066\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|#####4       | 42/100 [23:10<50:19, 52.07s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  61.467538833618164\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 43%|#####5       | 43/100 [24:02<49:24, 52.01s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  319.3786277770996\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|#####7       | 44/100 [24:54<48:36, 52.09s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  205.52429962158203\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|#####8       | 45/100 [25:46<47:46, 52.12s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  314.5286331176758\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 46%|#####9       | 46/100 [26:38<46:58, 52.20s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  232.82881927490234\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|######1      | 47/100 [27:31<46:07, 52.21s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  187.8083152770996\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|######2      | 48/100 [28:24<45:27, 52.45s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  117.86389350891113\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 49%|######3      | 49/100 [29:16<44:32, 52.39s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  353.3605308532715\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|######5      | 50/100 [30:08<43:36, 52.33s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  102.0417251586914\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 51%|######6      | 51/100 [31:00<42:43, 52.32s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  137.8079433441162\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|######7      | 52/100 [31:53<41:50, 52.30s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  131.6690273284912\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|######8      | 53/100 [32:45<40:56, 52.27s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  221.89770889282227\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 54%|#######      | 54/100 [33:37<40:04, 52.27s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  127.80197811126709\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|#######1     | 55/100 [34:29<39:09, 52.22s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  173.90100479125977\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|#######2     | 56/100 [35:22<38:20, 52.28s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  131.25774955749512\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 57%|#######4     | 57/100 [36:14<37:28, 52.30s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  352.5038814544678\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|#######5     | 58/100 [37:07<36:41, 52.42s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  284.5538387298584\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|#######6     | 59/100 [37:59<35:46, 52.35s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  303.74771881103516\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 60%|#######8     | 60/100 [38:51<34:57, 52.43s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  203.67033767700195\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|#######9     | 61/100 [39:44<34:04, 52.41s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  266.7119483947754\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|########     | 62/100 [40:36<33:12, 52.43s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  463.91573333740234\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 63%|########1    | 63/100 [41:29<32:18, 52.39s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  336.9028720855713\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|########3    | 64/100 [42:21<31:24, 52.35s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  249.80004501342773\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 65%|########4    | 65/100 [43:13<30:35, 52.43s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  304.1552782058716\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|########5    | 66/100 [44:06<29:44, 52.48s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  427.12571716308594\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|########7    | 67/100 [44:59<28:56, 52.63s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  174.53973054885864\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 68%|########8    | 68/100 [45:52<28:03, 52.60s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  274.0922260284424\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|########9    | 69/100 [46:44<27:12, 52.67s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  376.7329349517822\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|#########1   | 70/100 [47:37<26:19, 52.67s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  132.95535278320312\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 71%|#########2   | 71/100 [48:30<25:27, 52.67s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  607.286226272583\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|#########3   | 72/100 [49:23<24:35, 52.69s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  75.46749877929688\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|#########4   | 73/100 [50:15<23:42, 52.67s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  251.83892440795898\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 74%|#########6   | 74/100 [51:08<22:52, 52.78s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  188.84575939178467\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|#########7   | 75/100 [52:01<21:58, 52.72s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  265.035608291626\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 76%|#########8   | 76/100 [52:54<21:06, 52.76s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  177.93677139282227\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|##########   | 77/100 [53:46<20:11, 52.69s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  379.73699951171875\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|##########1  | 78/100 [54:39<19:19, 52.69s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  244.974027633667\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 79%|##########2  | 79/100 [55:32<18:26, 52.70s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  162.58155059814453\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|##########4  | 80/100 [56:24<17:34, 52.71s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  96.4915943145752\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|##########5  | 81/100 [57:17<16:43, 52.81s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  79.2655143737793\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 82%|##########6  | 82/100 [58:10<15:50, 52.78s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  241.63865280151367\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|##########7  | 83/100 [59:03<14:58, 52.85s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  354.01548957824707\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|##########9  | 84/100 [59:56<14:05, 52.85s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  487.45042991638184\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 85%|#########3 | 85/100 [1:00:48<13:10, 52.69s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  553.5917377471924\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|#########4 | 86/100 [1:01:40<12:15, 52.55s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  148.7508373260498\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 87%|#########5 | 87/100 [1:02:33<11:23, 52.57s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  630.3593339920044\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|#########6 | 88/100 [1:03:25<10:30, 52.52s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  141.86521911621094\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|#########7 | 89/100 [1:04:18<09:38, 52.57s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  459.29959297180176\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 90%|#########9 | 90/100 [1:05:11<08:46, 52.68s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  351.3422222137451\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|########## | 91/100 [1:06:04<07:54, 52.68s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  192.29705357551575\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|##########1| 92/100 [1:06:58<07:04, 53.09s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  209.3719940185547\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 93%|##########2| 93/100 [1:07:50<06:10, 52.91s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  196.56145477294922\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|##########3| 94/100 [1:08:43<05:16, 52.73s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  203.95548629760742\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|##########4| 95/100 [1:09:40<04:31, 54.21s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  175.98072052001953\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 96%|##########5| 96/100 [1:10:36<03:38, 54.72s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  319.5772590637207\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|##########6| 97/100 [1:11:32<02:45, 55.18s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  128.53872108459473\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|##########7| 98/100 [1:12:27<01:49, 54.97s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  263.69483375549316\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 99%|##########8| 99/100 [1:13:22<00:55, 55.12s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  216.68279647827148\n",
      "Reset the position to (0,0,0)\n",
      "Episode reached max number of steps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|##########| 100/100 [1:14:16<00:00, 44.57s/episodes]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode reward:  325.525297164917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# This is where the magic happens\n",
    "EPISODES = 100\n",
    "AGGREGATE_STATS_EVERY = 1 # Episode\n",
    "ep_rewards = []\n",
    "SHOW_PREVIEW = True\n",
    "MIN_REWARD = -10_000 # Rewards below this are not saved\n",
    "MODEL_NAME = \"LAUV_ROALD\"\n",
    "\n",
    "# Epsilon parameters determine the extent to which the agent will explore/exploit\n",
    "    # Using decaying epsilon: The more the agent learns, the less it will explore\n",
    "    # epsilon := Change of doing explore action, i.e. randomly select action\n",
    "    # EPSILON_DECAY := The rate at which exploring decays\n",
    "    # MIN_EPSILON := To always keep some level of exploration, exploration will not decay beyond this threshold\n",
    "\n",
    "epsilon = 1 # Not constant, as it will decay\n",
    "EPSILON_DECAY = 0.99975\n",
    "MIN_EPSILON = 0.001\n",
    "\n",
    "\n",
    "for episode in tqdm(range(1, EPISODES + 1), ascii=True, unit='episodes'):\n",
    "    \n",
    "    # Update tensorboard step every episode\n",
    "    agent.tensorboard.step = episode\n",
    "    \n",
    "    # Reset episode, rewards, environment, done-flag\n",
    "    episode_reward = 0\n",
    "    step = 1\n",
    "    current_state = env.reset()\n",
    "    agent.reset()\n",
    "    done = False\n",
    "    \n",
    "    # The training loop\n",
    "    while not done:\n",
    "        # Decide explore vs exploit\n",
    "        if np.random.random() > epsilon:\n",
    "            # Get action from Q table\n",
    "            action = np.argmax(agent.get_qs(current_state))\n",
    "        else:\n",
    "            # Get random action\n",
    "            action = np.random.randint(0, env.action_space.nvec[0])\n",
    "\n",
    "        # Take selected aciton\n",
    "        new_state, reward, done, _info = env.step([action])\n",
    "        next_pos = agent.deliberate(new_state)\n",
    "        \n",
    "        episode_reward+=reward\n",
    "    \n",
    "        if SHOW_PREVIEW:\n",
    "            agent.render(new_state, next_action)\n",
    "            env.render()\n",
    "\n",
    "        # Update replay-memory (a set length collection of experiences the agent remembers, from which training examples are selected)\n",
    "        # Works as a deque: one in, oldest out\n",
    "        #print(\"Updating replay memory...\")\n",
    "        agent.update_replay_memory((current_state, action, reward, new_state, done))\n",
    "\n",
    "        # Trains the agent with the replay-memory is sufficiently large\n",
    "        agent.train(done, step)\n",
    "        current_state = new_state\n",
    "        step += 1\n",
    "        \n",
    "    print(\"Episode reward: \", episode_reward)\n",
    "    \n",
    "    # Decay epsilon\n",
    "    if epsilon > MIN_EPSILON:\n",
    "        epsilon *= EPSILON_DECAY\n",
    "        epsilon = max(MIN_EPSILON, epsilon)\n",
    "        \n",
    "    # Logging and storing\n",
    "    ep_rewards.append(episode_reward)\n",
    "    if not episode % AGGREGATE_STATS_EVERY or episode == 1:\n",
    "        average_reward = sum(ep_rewards[-AGGREGATE_STATS_EVERY:])/len(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "        min_reward = min(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "        max_reward = max(ep_rewards[-AGGREGATE_STATS_EVERY:])\n",
    "        agent.tensorboard.update_stats(reward_avg=average_reward, reward_min=min_reward, reward_max=max_reward, epsilon=epsilon)\n",
    "\n",
    "        # Save model, but only when min reward is greater or equal a set value\n",
    "        if min_reward >= MIN_REWARD:\n",
    "            agent.model.save(f'models/{MODEL_NAME}__{max_reward:_>7.2f}max_{average_reward:_>7.2f}avg_{min_reward:_>7.2f}min__{int(time.time())}.model')\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
